#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Nano Banana (Gemini) å›¾ç‰‡ç”Ÿæˆå™¨
åŸºäºŽ OpenAI å…¼å®¹åè®® (Requests)
"""

import json
import requests
import time
from typing import Dict, Optional
import os
import base64
import re

class ImageGenerator:
    """åŸºäºŽ HTTP è¯·æ±‚çš„é€šç”¨å›¾ç‰‡ç”Ÿæˆå™¨"""

    def __init__(self, config_path: str = None):
        if config_path is None:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            config_path = os.path.join(base_dir, "..", "data", "config.json")
            
        self.config_path = config_path
        self.config = self._load_config(config_path)
        self._apply_config(self.config)

    def _load_config(self, config_path: str) -> Dict:
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return {}

    def _apply_config(self, config: Dict):
        """å°†é…ç½®å­—å…¸åº”ç”¨åˆ°å®žä¾‹å±žæ€§"""
        if not isinstance(config, dict):
            config = {}
        self.config = config
        api_cfg = self.config.get("api", {}) or {}
        auth_cfg = self.config.get("auth", {}) or {}
        # ç¡®ä¿ image èŠ‚ç‚¹å­˜åœ¨ï¼Œé¿å…ä¸‹æ¸¸ KeyError
        self.config.setdefault("image", {})

        # åŠ è½½é…ç½®ï¼ˆä»¥ config æ–‡ä»¶ä¸ºä¸»ï¼‰
        self.base_url = api_cfg.get("base_url", "").rstrip("/")
        
        # Load keys
        primary_key = auth_cfg.get("api_key", "")
        # Load backup keys (from config or env)
        # Env var BACKUP_KEYS takes precedence? Or config?
        # Let's support config 'backup_keys' which is a list or string
        backup_keys_conf = auth_cfg.get("backup_keys", [])
        if isinstance(backup_keys_conf, str):
            backup_keys_conf = [k.strip() for k in backup_keys_conf.split(",") if k.strip()]
        
        self.api_keys = [k for k in [primary_key] + backup_keys_conf if k]
        self.api_key = self.api_keys[0] if self.api_keys else ""
        
        # Load model-specific keys
        model_rules = auth_cfg.get("model_rules", {})
        self.special_models = model_rules.get("special_models", [])
        self.special_keys = model_rules.get("special_keys", [])
        if isinstance(self.special_keys, str):
             self.special_keys = [k.strip() for k in self.special_keys.split(",") if k.strip()]
        
        self.model = api_cfg.get("model")
        
        self.timeout = api_cfg.get("timeout", 120)
        self.max_retries = api_cfg.get("max_retries", 3)

    def _execute_raw_request(self, url: str, headers: Dict, data: Dict, retry_count: int = 0) -> Optional[requests.Response]:
        """æ‰§è¡Œå•æ¬¡è¯·æ±‚ï¼Œå¤„ç†ç½‘ç»œå±‚é¢çš„é‡è¯•"""
        try:
            print(f"ðŸš€ å‘é€è¯·æ±‚åˆ°: {url}")
            print(f"   æ¨¡åž‹: {data.get('model')}")
            
            response = requests.post(
                url,
                headers=headers,
                json=data,
                timeout=self.timeout
            )
            return response
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            return None

    def _make_request(self, endpoint: str, data: Dict, retry_count: int = 0, base_url: str = None, api_key: str = None, model: str = None) -> Optional[Dict]:
        """å‘é€APIè¯·æ±‚ (æ”¯æŒå¤šKeyè½®è¯¢)"""
        current_base_url = (base_url or self.base_url).rstrip("/")
        
        # Override model in data if provided
        if model:
            data["model"] = model
            
        url = f"{current_base_url}{endpoint}"
        
        # Determine keys to try
        # If explicit api_key provided (BYOK), use only that.
        # Otherwise, use system keys (primary + backups).
        keys_to_try = [api_key] if api_key else (self.api_keys if self.api_keys else [""])

        # Check for model-specific keys override (System keys only)
        if not api_key and model and model in self.special_models and self.special_keys:
             print(f"ðŸ”‘ ä½¿ç”¨ä¸“ç”¨Keyæ±  (é’ˆå¯¹æ¨¡åž‹: {model})")
             keys_to_try = self.special_keys
        
        last_error = None
        
        for key_idx, current_key in enumerate(keys_to_try):
            headers = {
                "Authorization": f"Bearer {current_key}",
                "Content-Type": "application/json"
            }
            
            # Internal Retry Loop for a specific key (for 502/Timeout etc, not 401/403)
            # Actually, _execute_raw_request handles the call. We handle logical retries here?
            # Let's keep simple: Try Key -> If 401/429/500 -> Try Next Key.
            # If 502/504 -> Retry same key a few times?
            
            # Let's combine: Loop over Keys. Inside, retry connection errors?
            # Simplified: Just try each key once. If network fails, maybe retry same key?
            
            # We will use a simple retry for network flakes on the *same* key
            for attempt in range(self.max_retries + 1):
                response = self._execute_raw_request(url, headers, data)
                
                if response is None:
                    # Network error, retry same key
                    time.sleep(1)
                    continue
                
                if response.status_code == 200:
                    return response.json()
                
                # If error is recoverable by switching keys (401 Auth, 429 Rate, 402 Payment, 500/503 Provider Error)
                if response.status_code in [401, 403, 429, 402, 500, 503]:
                    print(f"âš ï¸ Key #{key_idx} failed with {response.status_code}. Trying next key...")
                    # Break inner loop (retries) to go to next key
                    break 
                
                # If error is likely transient (502, 504), retry same key
                if response.status_code in [502, 504]:
                     print(f"ðŸ”„ æ­£åœ¨é‡è¯• ({attempt + 1}/{self.max_retries})...")
                     time.sleep(2)
                     continue
                
                # Other errors (400 Bad Request) -> Don't switch keys, likely request issue
                print(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                print(f"   å“åº”: {response.text}")
                return None
            
            # If we broke out of inner loop, it means this key failed. Continue to next key.
            
        print("âŒ All keys failed.")
        return None

    def _generate_image_via_chat(self, prompt: str, size: str = None, quality: str = None, base_url: str = None, api_key: str = None, model: str = None) -> Optional[str]:
        """é€šè¿‡ Chat API ç”Ÿæˆå›¾ç‰‡ (é’ˆå¯¹ Gemini ç­‰æ¨¡åž‹)"""
        
        # é’ˆå¯¹ Gemini çš„ Prompt å¢žå¼º: æ³¨å…¥ç”»å¹…æ¯”ä¾‹æŒ‡ä»¤
        final_prompt = prompt
        
        # 1. ç”»å¹…å¤„ç†
        if size:
            if size == "1792x1024":
                final_prompt += " --ar 16:9"
            elif size == "1024x1792":
                final_prompt += " --ar 9:16"
            elif size == "1024x1024":
                final_prompt += " --ar 1:1"
        
        # 2. ç”»è´¨/åˆ†è¾¨çŽ‡å¤„ç† (é€šè¿‡æç¤ºè¯å¢žå¼º)
        # è™½ç„¶ç‰©ç†åˆ†è¾¨çŽ‡å—é™ï¼Œä½†é€šè¿‡æŒ‡ä»¤å¯ä»¥æ˜¾è‘—æå‡ç»†èŠ‚å¯†åº¦
        if quality:
            if quality.lower() in ["2k", "high"]:
                final_prompt += ", (highly detailed, 2k resolution, sharp focus)"
            elif quality.lower() in ["4k", "ultra"]:
                final_prompt += ", (ultra detailed, 4k resolution, 8k, masterpiece, best quality, extreme detail, hyperrealistic)"

        print(f"ðŸŽ¨ Chatç”Ÿæˆæç¤ºè¯: {final_prompt}")

        data = {
            "model": model or self.model,
            "messages": [
                {"role": "user", "content": final_prompt}
            ],
            "n": 1
        }
        
        response = self._make_request("/v1/chat/completions", data, base_url=base_url, api_key=api_key, model=model)
        
        if response and "choices" in response and len(response["choices"]) > 0:
            content = response["choices"][0]["message"]["content"]
            # å°è¯•æå– markdown å›¾ç‰‡é“¾æŽ¥æˆ–ç›´æŽ¥è¿”å›žå†…å®¹
            # æ ¼å¼é€šå¸¸æ˜¯ ![image](url) æˆ– ![image](data:image/...)
            match = re.search(r'!\[.*?\]\((.*?)\)', content)
            if match:
                return match.group(1)
            return content # å¦‚æžœæ²¡æ‰¾åˆ°markdownæ ¼å¼ï¼Œç›´æŽ¥è¿”å›žå†…å®¹å°è¯•
        return None

    def optimize_prompt(self, raw_prompt: str, subject: str = "general", model: str = None) -> str:
        """
        ä½¿ç”¨ LLM ä¼˜åŒ–æç¤ºè¯ (èžå…¥ç»“æž„åŒ–æ€ç»´)
        :param model: ç›®æ ‡ç»˜å›¾æ¨¡åž‹ (Target Image Model)ï¼Œç”¨äºŽå®šåˆ¶æç¤ºè¯é£Žæ ¼ã€‚
                      å®žé™…æŽ¨ç†ä»ç„¶ä½¿ç”¨ self.model (System LLM)ã€‚
        """
        # 1. ç¡®å®š LLM å’Œ ç›®æ ‡é£Žæ ¼
        llm_model = self.model # å§‹ç»ˆä½¿ç”¨ç³»ç»Ÿé…ç½®çš„ LLM (Brain) è¿›è¡Œæ€è€ƒ
        target_model = model or self.model # ç”¨æˆ·é€‰æ‹©çš„ç»˜å›¾æ¨¡åž‹
        
        # 2. å®šä¹‰å­¦ç§‘ç‰¹å®šçš„è´Ÿé¢çº¦æŸ
        subject_constraints = {
            "math": "no distorted numbers, no curved rulers, no incorrect formulas",
            "science": "no pseudo-science, no incorrect anatomy, no impossible physics",
            "physics": "no impossible physics, correct diagrams",
            "chemistry": "no incorrect molecules, realistic equipment",
            "biology": "correct anatomy, realistic plants/animals",
            "english": "no gibberish text, no asian characters, spelling must be correct",
            "chinese": "calligraphy style, correct characters",
            "history": "no anachronisms, period-accurate clothing only",
            "it_ai": "no blurry screens, no nonsensical code, futuristic but logical",
            "arts_pe": "aesthetic, dynamic composition, correct musical instruments, realistic sports action",
            "humanities_psych": "accurate maps, historical accuracy, biological details, empathy, facial expressions, social scenes",
            "textbook": "no blurry details, no photographic noise, no dark background, no complex background"
        }
        
        neg_constraint = subject_constraints.get(subject, "no distorted text, no blurry details")

        # 3. å®šåˆ¶åŒ–é£Žæ ¼æŒ‡ä»¤ (æ ¹æ®ç›®æ ‡æ¨¡åž‹)
        style_instruction = ""
        if target_model:
            t_lower = target_model.lower()
            if "jimeng" in t_lower:
                style_instruction = "Target Model: Jimeng/Dream. Style preference: High artistic quality, dreamy lighting, Chinese aesthetic friendly, precise tags."
            elif "gpt" in t_lower or "dall" in t_lower:
                style_instruction = "Target Model: DALL-E 3. Style preference: Natural language descriptions, very literal interpretation, detailed visual adjectives."
            elif "gemini" in t_lower:
                style_instruction = "Target Model: Gemini Image. Style preference: Structured, logical, high dynamic range, prompt adherence."

        # 4. é«˜çº§ System Prompt
        
        # é’ˆå¯¹â€œæ•™æç»˜å›¾â€çš„ç‰¹æ®Šå¤„ç†
        if subject == "textbook":
            style_keywords = "modern 2.5D vector illustration, soft gradient shading, clean lines, high-quality educational textbook art, vibrant multi-color accents, white background"
            
            system_instruction = f"""
You are a Prompt Engineering Expert. Your task is to WRITE A TEXT DESCRIPTION.
DO NOT GENERATE AN IMAGE.

Goal: Rewrite the user's input into a detailed visual description suitable for an image generator.
Constraint: {neg_constraint}.
Background: Must be White.
{style_instruction}

Process:
1. Analyze the core concept.
2. Write a descriptive paragraph in English.
3. Integrate the style requirements naturally.

Output ONLY the text description.
"""
            user_content = f"Create a textbook illustration prompt for: {raw_prompt}. Style requirements: {style_keywords}. Subject context: {subject}"
        else:
            system_instruction = f"""
You are a Prompt Engineering Expert. Your task is to WRITE A TEXT DESCRIPTION.
DO NOT GENERATE AN IMAGE.

Goal: Rewrite the user's input into a structured prompt.
Constraint: {neg_constraint}.
{style_instruction}

Output ONLY the text description.
"""
            user_content = f"Create an educational infographic prompt for: {raw_prompt}. Subject context: {subject}"
        
        # æ³¨æ„: è¿™é‡Œä½¿ç”¨ llm_model (self.model) å‘èµ·è¯·æ±‚ï¼Œè€Œä¸æ˜¯ä¼ å…¥çš„ model (å¯èƒ½åªæ˜¯ image model)
        data = {
            "model": llm_model, 
            "messages": [
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": user_content}
            ],
            "temperature": 0.7
        }
        
        print(f"âœ¨ æ­£åœ¨ä¼˜åŒ–æç¤ºè¯ (Target: {target_model}): {raw_prompt}")
        response = self._make_request("/v1/chat/completions", data, model=llm_model)
        
        if response and "choices" in response and len(response["choices"]) > 0:
            content = response["choices"][0]["message"]["content"].strip()
            
            # ç§»é™¤ markdown å›¾ç‰‡é“¾æŽ¥
            content = re.sub(r'!\[.*?\]\(.*?\)', '', content)
            content = re.sub(r'\[Image\]', '', content, flags=re.IGNORECASE)
            content = content.strip()
            
            if not content or len(content) < 5:
                print("âš ï¸ ä¼˜åŒ–ç»“æžœæ— æ•ˆï¼Œå›žé€€")
                return raw_prompt

            print(f"âœ¨ ä¼˜åŒ–å®Œæˆ: {content[:50]}...")
            return content
        
        return raw_prompt

    def generate_modified_image(self, prompt: str, base_image_paths: list[str], base_url: str = None, api_key: str = None, model: str = None) -> Optional[str]:
        """
        åŸºäºŽåŽŸå›¾(å¤šå›¾)è¿›è¡Œä¿®æ”¹ (Image-to-Image / Vision)
        """
        if not base_image_paths:
            return None

        try:
            content_list = [
                {
                    "type": "text",
                    "text": f"{prompt} (Return the modified image URL only)"
                }
            ]

            for img_path in base_image_paths:
                if not os.path.exists(img_path):
                    print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„å›¾ç‰‡: {img_path}")
                    continue
                    
                # ç¡®å®šMIMEç±»åž‹
                mime_type = "image/png"
                if img_path.lower().endswith(".jpg") or img_path.lower().endswith(".jpeg"):
                    mime_type = "image/jpeg"
                
                # è¯»å–å¹¶ç¼–ç 
                with open(img_path, "rb") as image_file:
                    encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
                
                content_list.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{mime_type};base64,{encoded_string}"
                    }
                })

            print(f"ðŸŽ¨ æ­£åœ¨ä¿®æ”¹å›¾ç‰‡ ({len(base_image_paths)} refs), æç¤ºè¯: {prompt}")

            # 2. æž„å»ºå¤šæ¨¡æ€è¯·æ±‚ (OpenAI Vision æ ¼å¼)
            data = {
                "model": model or self.model,
                "messages": [
                    {
                        "role": "user",
                        "content": content_list
                    }
                ],
                "n": 1
            }

            response = self._make_request("/v1/chat/completions", data, base_url=base_url, api_key=api_key, model=model)

            if response and "choices" in response and len(response["choices"]) > 0:
                content = response["choices"][0]["message"]["content"]
                # å°è¯•æå– markdown å›¾ç‰‡é“¾æŽ¥
                match = re.search(r'!\[.*?\]\((.*?)\)', content)
                if match:
                    return match.group(1)
                # å‡å¦‚ç›´æŽ¥è¿”å›žäº†URLæ–‡æœ¬
                if content.startswith("http"):
                    return content
                return content
            return None

        except Exception as e:
            print(f"âŒ å›¾ç‰‡ä¿®æ”¹å¤±è´¥: {e}")
            return None

    def generate_image(self, prompt: str, size: str = None, quality: str = None, style: str = None, base_url: str = None, api_key: str = None, model: str = None) -> Optional[str]:
        """
        ç”Ÿæˆå›¾ç‰‡
        Returns: å›¾ç‰‡ URL æˆ– Base64 Data URI
        """
        # ä½¿ç”¨é»˜è®¤å‚æ•°
        if size is None: size = self.config["image"].get("size")
        if quality is None: quality = self.config["image"].get("quality")
        if style is None: style = self.config["image"].get("style")
        
        target_model = model or self.model

        # é’ˆå¯¹ Gemini-3-pro-image-preview æ¨¡åž‹çš„ç‰¹æ®Šå¤„ç†
        if "gemini-3-pro-image-preview" in target_model:
            print(f"ðŸ¤– æ£€æµ‹åˆ° Gemini ç»˜å›¾æ¨¡åž‹ï¼Œåˆ‡æ¢åˆ° Chat æŽ¥å£...")
            return self._generate_image_via_chat(prompt, size, quality, base_url=base_url, api_key=api_key, model=target_model)

        # æž„å»ºè¯·æ±‚æ•°æ® (OpenAI å…¼å®¹æ ¼å¼)
        data = {
            "model": target_model,
            "prompt": prompt,
            "n": 1,
            "size": size,
            "response_format": "url"
        }

        # é’ˆå¯¹ z-image-turbo çš„ç‰¹æ®Šå‚æ•°
        if target_model == "z-image-turbo":
            data.update({
                "watermark": False,
                "prompt_extend": True
            })

        # å¤§å¤šæ•°ä¸­è½¬å•†ä½¿ç”¨æ ‡å‡†çš„ OpenAI å›¾ç‰‡æŽ¥å£
        response = self._make_request("/v1/images/generations", data, base_url=base_url, api_key=api_key, model=target_model)

        if response and "data" in response and len(response["data"]) > 0:
            image_url = response["data"][0]["url"]
            print(f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸURL: {image_url[:50]}...")
            return image_url
        else:
            print("âŒ æœªèŽ·å–åˆ°å›¾ç‰‡æ•°æ®")
            return None

    def download_image(self, image_url: str, save_path: str) -> bool:
        """ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ° (æ”¯æŒ URL å’Œ Base64 Data URI)"""
        try:
            print(f"ðŸ“¥ å‡†å¤‡ä¿å­˜å›¾ç‰‡åˆ°: {save_path}")
            os.makedirs(os.path.dirname(save_path), exist_ok=True)

            # å¤„ç† Base64 Data URI
            if image_url.startswith("data:image"):
                try:
                    # æ ¼å¼: data:image/png;base64,.....
                    header, encoded = image_url.split(",", 1)
                    data = base64.b64decode(encoded)
                    with open(save_path, 'wb') as f:
                        f.write(data)
                    print(f"âœ… Base64å›¾ç‰‡è§£ç å¹¶ä¿å­˜æˆåŠŸ")
                    return True
                except Exception as e:
                    print(f"âŒ Base64è§£ç å¤±è´¥: {e}")
                    return False

            # å¤„ç†æ™®é€š URL
            # æœ‰äº› URL éœ€è¦ä»£ç†ï¼Œæœ‰äº›ä¸éœ€è¦ï¼Œè¿™é‡Œç›´æŽ¥è¯·æ±‚
            response = requests.get(image_url, timeout=60)

            if response.status_code == 200:
                with open(save_path, 'wb') as f:
                    f.write(response.content)
                print(f"âœ… ä¸‹è½½æˆåŠŸ")
                return True
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¼‚å¸¸: {e}")
            return False

    def generate_and_download(self, prompt: str, filename: str, folder: str = "generated_images", base_url: str = None, api_key: str = None, model: str = None) -> Optional[str]:
        """ç”Ÿæˆå¹¶ä¸‹è½½"""
        image_url = self.generate_image(prompt, base_url=base_url, api_key=api_key, model=model)
        
        if image_url:
            save_path = os.path.join(folder, filename)
            if self.download_image(image_url, save_path):
                return save_path
        return None

# å•ä¾‹è¾…åŠ©å‡½æ•°
def get_image_generator() -> ImageGenerator:
    return ImageGenerator()
